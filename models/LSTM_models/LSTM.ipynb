{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first dowloand 7train1.csv data file. Then after y\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"/content/drive/My Drive/7Train1.csv\", header=None)\n",
    "bandwidth = data.iloc[:, 0].values  # Convert to NumPy array\n",
    "length = len(bandwidth)\n",
    "mean=np.mean(bandwidth)\n",
    "len_train = math.floor(length * 0.8)\n",
    "for i in range(length):\n",
    "  if bandwidth[i] > 40:\n",
    "     bandwidth[i] = 0\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "bandwidth_normalized = scaler.fit_transform(bandwidth.reshape(-1, 1))\n",
    "\n",
    "\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "data_tensor = torch.FloatTensor(bandwidth_normalized).view(-1, 1)\n",
    "\n",
    "# prediction size\n",
    "predict_size=1\n",
    "\n",
    "# Function to create in-out sequences\n",
    "def create_inout_sequences(input_data, window_size,predict_size):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L - window_size-predict_size+1):\n",
    "        train_seq = input_data[i:i + window_size]\n",
    "        train_label = input_data[i + window_size:i + window_size + predict_size]\n",
    "        inout_seq.append((train_seq, train_label))\n",
    "    return inout_seq\n",
    "\n",
    "# Parameters\n",
    "window_size = 5\n",
    "\n",
    "batch_size=4\n",
    "# Create sequences for training from the first part of the data\n",
    "train_inout_seq = create_inout_sequences(data_tensor[:len_train], window_size,predict_size)\n",
    "\n",
    "\n",
    "# Custom dataset class\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx]\n",
    "\n",
    "# Create DataLoader for training\n",
    "train_dataset = TimeSeriesDataset(train_inout_seq)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "# Create sequences for testing from the remaining part of the data\n",
    "test_inout_seq = create_inout_sequences(data_tensor[len_train:], window_size,predict_size)\n",
    "\n",
    "\n",
    "# Define LSTM model with adjustable number of layers and dropout\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=128, output_size=predict_size, num_layers=2, dropout=0.5):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers, dropout=dropout,batch_first=False)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq, hidden_state):\n",
    "        lstm_out, hidden_state = self.lstm(input_seq, hidden_state)\n",
    "        predictions = self.linear(lstm_out[:,-1,:])\n",
    "        return predictions[-1], hidden_state\n",
    "\n",
    "    def init_hidden(self,batch_size):\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.hidden_layer_size),\n",
    "                torch.zeros(self.num_layers, batch_size, self.hidden_layer_size))\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = LSTM(dropout=0.2, num_layers=2)  # Adjust the dropout rate and number of layers as needed\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "epochs = 30\n",
    "train_losses = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    hidden_state = model.init_hidden(batch_size)  # Initialize hidden state for each epoch\n",
    "\n",
    "    epoch_train_loss = 0\n",
    "    for seq, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        seq = seq.view(window_size, batch_size, -1)  # Reshape for LSTM input\n",
    "        labels = labels.view(batch_size, -1)\n",
    "\n",
    "        y_pred, hidden_state = model(seq, hidden_state)\n",
    "\n",
    "        # Detach hidden state to prevent backpropagating through the entire history\n",
    "        hidden_state = (hidden_state[0].detach(), hidden_state[1].detach())\n",
    "\n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_train_loss += single_loss.item()\n",
    "\n",
    "    train_losses.append(epoch_train_loss / len(train_inout_seq))\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {single_loss.item():.8f}')\n",
    "\n",
    "# Making predictions\n",
    "model.eval()\n",
    "hidden_state = model.init_hidden(1)\n",
    "\n",
    "predictions = []\n",
    "for seq, _ in test_inout_seq:\n",
    "    seq = seq.view(-1, 1, 1)  # Reshape for LSTM input\n",
    "    with torch.no_grad():\n",
    "        y_pred, hidden_state = model(seq, hidden_state)\n",
    "        hidden_state = (hidden_state[0].detach(), hidden_state[1].detach())\n",
    "        predictions.append(y_pred[predict_size-1].item())\n",
    "\n",
    "# Convert predictions back to original scale\n",
    "predictions = scaler.inverse_transform(np.array(predictions).reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate actual values\n",
    "actual_values = bandwidth[len_train + window_size+predict_size-1:]\n",
    "\n",
    "# Calculate MAE and RMSE for all test data\n",
    "mae = mean_absolute_error(actual_values, predictions)\n",
    "rmse = np.sqrt(mean_squared_error(actual_values, predictions))\n",
    "\n",
    "# Calculate error ratio as defined\n",
    "mean_actual = np.mean(actual_values)\n",
    "error_ratio_rmse = (rmse / mean_actual) * 100\n",
    "error_ratio_mae = (mae / mean_actual) * 100\n",
    "\n",
    "print(f'Mean Absolute Error (MAE): {mae:.4f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.4f}')\n",
    "print(f'Error Ratio RMSE: {error_ratio_rmse:.4f}%')\n",
    "print(f'Error Ratio MAE: {error_ratio_mae:.4f}%')\n",
    "\n",
    "# Slice to get some 195 values for plotting\n",
    "predictions_195 = predictions[:195]\n",
    "\n",
    "\n",
    "actual_values_195 = actual_values[:195]\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len_train + window_size, len_train + window_size + 195), actual_values_195, label='Actual Data')\n",
    "plt.plot(range(len_train + window_size, len_train + window_size + 195), predictions_195, label='LSTM Predctions')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Bandwidth\")\n",
    "plt.title(\"LSTM Predictions vs Actual Data (First 195 values from 3000 onwards)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
