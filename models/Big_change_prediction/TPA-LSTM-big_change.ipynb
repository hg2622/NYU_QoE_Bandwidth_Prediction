{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"/content/drive/My Drive/7Train1.csv\", header=None)\n",
    "\n",
    "# Function to create big drop labels for the training dataset (threshold = 5)\n",
    "def add_big_drop_label_train(bandwidth, threshold=5):\n",
    "    big_drop = []\n",
    "    for i in range(0, len(bandwidth)-1):\n",
    "        diff = abs(bandwidth[i+1] - bandwidth[i])\n",
    "        big_drop.append(1 if diff >= threshold else 0)\n",
    "    return big_drop + [0]  # Add initial 0 for the first value\n",
    "\n",
    "# Function to create big drop labels for the testing dataset (threshold = 3)\n",
    "def add_big_drop_label_test(bandwidth, threshold=5):\n",
    "    big_drop = []\n",
    "    for i in range(1, len(bandwidth)):\n",
    "        diff = abs(bandwidth[i] - bandwidth[i-1])\n",
    "        big_drop.append(1 if diff >= threshold else 0)\n",
    "    return [0] + big_drop  # Add initial 0 for first value\n",
    "\n",
    "# Prepare bandwidth and big drop labels for the training set\n",
    "bandwidth = data.iloc[:, 0].values  # Convert to NumPy array\n",
    "len_train = math.floor(len(bandwidth) * 0.8)\n",
    "\n",
    "for i in range(len(bandwidth)):\n",
    "    if bandwidth[i] > 30:\n",
    "        bandwidth[i] = 0\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "bandwidth_normalized = scaler.fit_transform(bandwidth.reshape(-1, 1))\n",
    "\n",
    "# Add big drop labels to the training dataset\n",
    "big_drop_labels_train = torch.tensor(add_big_drop_label_train(bandwidth), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Combine bandwidth and big drop labels for the training dataset\n",
    "input_features_train = np.column_stack((bandwidth_normalized, big_drop_labels_train))\n",
    "\n",
    "# Convert to PyTorch tensor (input will have 2 features per timestep now)\n",
    "data_tensor_train = torch.FloatTensor(input_features_train)\n",
    "\n",
    "# Add big drop labels to the testing dataset with the modified threshold (threshold = 5)\n",
    "bandwidth_test = bandwidth_normalized[len_train:]\n",
    "\n",
    "data_tensor_test = torch.FloatTensor([0,0,0,0,0]+[x>=0.5 for x in test_predictions])\n",
    "big_drop_labels_test = torch.tensor(add_big_drop_label_test(data_tensor_test), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Manually define test features\n",
    "# Assuming you want to input your own test features for the test set\n",
    "\n",
    "\n",
    "# Convert to PyTorch tensor for the test set\n",
    "# Assuming the previous part of the code where you have bandwidth and test predictions ready.\n",
    "\n",
    "# Combine the test predictions with the original bandwidth to form a new dataset with two features\n",
    "def create_test_features_with_predictions(bandwidth_test, predictions):\n",
    "    # Ensure bandwidth_test and predictions have the same length\n",
    "    assert len(bandwidth_test) == len(predictions), \"Bandwidth and predictions lengths must match.\"\n",
    "\n",
    "    # Combine bandwidth and predictions into a 2D array (two features)\n",
    "    test_features = np.column_stack((bandwidth_test, predictions))\n",
    "\n",
    "    return test_features\n",
    "\n",
    "# Assuming `bandwidth_test` and `predictions` are already defined:\n",
    "test_features_with_predictions = create_test_features_with_predictions(bandwidth_test, data_tensor_test)\n",
    "\n",
    "# Convert to PyTorch tensor for further use\n",
    "data_tensor_test_with_predictions = torch.FloatTensor(test_features_with_predictions)\n",
    "\n",
    "# Now, you can use this combined feature set for any further processing or model predictions\n",
    "\n",
    "\n",
    "\n",
    "# Prediction size\n",
    "predict_size = 1\n",
    "\n",
    "# Function to create in-out sequences\n",
    "def create_inout_sequences_with_big_drop(input_data, big_drop_labels, window_size, predict_size):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L - window_size - predict_size + 1):\n",
    "        train_seq = input_data[i:i + window_size, :]\n",
    "        train_label_bandwidth = input_data[i + window_size:i + window_size + predict_size, 0]  # Predict only bandwidth\n",
    "        train_label_big_drop = big_drop_labels[i + window_size:i + window_size + predict_size]\n",
    "        inout_seq.append((train_seq, (train_label_bandwidth, train_label_big_drop)))\n",
    "    return inout_seq\n",
    "\n",
    "# Parameters\n",
    "window_size = 5\n",
    "batch_size = 4\n",
    "\n",
    "# Create sequences for training from the first part of the data\n",
    "train_inout_seq = create_inout_sequences_with_big_drop(input_features_train[:len_train], big_drop_labels_train, window_size, predict_size)\n",
    "\n",
    "# Custom dataset class\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx]\n",
    "\n",
    "# Create DataLoader for training\n",
    "train_dataset = TimeSeriesDataset(train_inout_seq)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "# Create sequences for testing using the user-defined test features\n",
    "test_inout_seq = create_inout_sequences_with_big_drop(test_features_with_predictions,big_drop_labels_test, window_size, predict_size)\n",
    "\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_layer_size, out_channel):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.linear = nn.Linear(out_channel, hidden_layer_size)\n",
    "\n",
    "    def forward(self, query, key, value):\n",
    "        # Ensure query, key, and value have compatible shapes\n",
    "        scores = torch.bmm(self.linear(key), query.unsqueeze(2))  # Adjusting to [batch_size, hidden_size, 1]\n",
    "        attn_weights = self.sigmoid(scores)\n",
    "        context = torch.bmm(attn_weights.transpose(1, 2), value)\n",
    "        return context, attn_weights\n",
    "\n",
    "\n",
    "class LSTMWithAttention(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=128, output_size_bandwidth=1, output_size_classification=1, num_layers=2, dropout=0.2, cnn_kernel_size=10, memory_size=16, out_channel=128):\n",
    "        super(LSTMWithAttention, self).__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.out_channel = out_channel\n",
    "        self.num_layers = num_layers\n",
    "        self.memory_size = memory_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers, dropout=dropout, batch_first=True)\n",
    "        self.attention = Attention(hidden_layer_size, out_channel)\n",
    "        self.cnn = nn.Linear(memory_size, out_channel)\n",
    "        self.linear_bandwidth = nn.Linear(hidden_layer_size, output_size_bandwidth)\n",
    "        self.linear_classification = nn.Linear(hidden_layer_size, output_size_classification)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, input_seq, hidden_state, past_hidden_states):\n",
    "        lstm_out, hidden_state = self.lstm(input_seq, hidden_state)\n",
    "        lstm_out_last = lstm_out[:, -1, :]  # Get the last time step\n",
    "\n",
    "        # Append new hidden state to past hidden states\n",
    "        past_hidden_states = torch.cat((past_hidden_states, lstm_out_last.unsqueeze(0)), dim=0)\n",
    "        if past_hidden_states.size(0) > self.memory_size:\n",
    "            past_hidden_states = past_hidden_states[-self.memory_size:]\n",
    "\n",
    "        # CNN on past hidden states\n",
    "        cnn_out = self.cnn(past_hidden_states.transpose(0, 1).transpose(1, 2))\n",
    "\n",
    "        # Attention mechanism\n",
    "        query = lstm_out_last  # Ensure query has same batch size as key\n",
    "        context, _ = self.attention(query, cnn_out, cnn_out)\n",
    "        \n",
    "        # Predictions\n",
    "        bandwidth_prediction = self.linear_bandwidth(context.squeeze(1))\n",
    "        big_drop_prediction = self.sigmoid(self.linear_classification(context.squeeze(1)))\n",
    "        return bandwidth_prediction, big_drop_prediction, hidden_state, past_hidden_states\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.hidden_layer_size),\n",
    "                torch.zeros(self.num_layers, batch_size, self.hidden_layer_size)) \n",
    "\n",
    "\n",
    "# Initialize the model, loss functions, and optimizer\n",
    "model = LSTMWithAttention(input_size=2, dropout=0.2, num_layers=2)\n",
    "mse_loss_function = nn.MSELoss()\n",
    "bce_loss_function = nn.BCELoss()  # Using BCE for classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Training the model\n",
    "epochs = 15\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_train_loss = 0\n",
    "    for seq, (labels_bandwidth, labels_big_drop) in train_loader:\n",
    "        hidden_state = model.init_hidden(batch_size)\n",
    "        past_hidden_states = torch.zeros(model.memory_size, batch_size, model.hidden_layer_size) \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        seq = seq.view(batch_size, window_size, 2).float()\n",
    "        labels_bandwidth = labels_bandwidth.view(batch_size, -1).float()\n",
    "        labels_big_drop = labels_big_drop.view(batch_size, -1).float()\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred_bandwidth, y_pred_big_drop, hidden_state, past_hidden_states = model(seq, hidden_state, past_hidden_states)\n",
    "        hidden_state = (hidden_state[0].detach(), hidden_state[1].detach())\n",
    "        past_hidden_states = past_hidden_states.detach()\n",
    "\n",
    "        # Calculate losses\n",
    "        bandwidth_loss = mse_loss_function(y_pred_bandwidth, labels_bandwidth)\n",
    "        classification_loss = bce_loss_function(y_pred_big_drop, labels_big_drop)\n",
    "        total_loss = bandwidth_loss + classification_loss\n",
    "\n",
    "        # Backward pass\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_train_loss += total_loss.item()\n",
    "\n",
    "    train_losses.append(epoch_train_loss / len(train_loader))\n",
    "    if epoch % 5 == 0:\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Total Loss: {epoch_train_loss / len(train_loader):.8f}')\n",
    "\n",
    "\n",
    "# Testing phase\n",
    "model.eval()\n",
    "hidden_state = model.init_hidden(1)\n",
    "past_hidden_states = torch.zeros(model.memory_size, 1, model.hidden_layer_size)\n",
    "\n",
    "predictions = []\n",
    "big_drop_predictions = []\n",
    "for seq, (labels_bandwidth, labels_big_drop) in test_inout_seq:\n",
    "    seq = torch.tensor(seq, dtype=torch.float32)\n",
    "    seq = seq.unsqueeze(0)\n",
    "    seq = seq.view(1, window_size, -1)  # Adjust input size t\n",
    "    with torch.no_grad():\n",
    "        y_pred_bandwidth, y_pred_big_drop, hidden_state, past_hidden_states = model(seq, hidden_state, past_hidden_states)\n",
    "        predictions.append(y_pred_bandwidth.item())\n",
    "        big_drop_predictions.append(y_pred_big_drop.item())\n",
    "        hidden_state = (hidden_state[0].detach(), hidden_state[1].detach())\n",
    "        past_hidden_states = past_hidden_states.detach()\n",
    "\n",
    "\n",
    "predictions = scaler.inverse_transform(np.array(predictions).reshape(-1, 1)).flatten()\n",
    "actual_values = bandwidth[len_train + window_size + predict_size - 1:]\n",
    "\n",
    "# Calculate MAE and RMSE for all test data\n",
    "# Calculate MAE and RMSE for all test data\n",
    "mae = mean_absolute_error(actual_values, predictions)\n",
    "rmse = np.sqrt(mean_squared_error(actual_values, predictions))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Mean Absolute Error (MAE) and RMSE Calculation\n",
    "print(f'Mean Absolute Error (MAE): {mae:.4f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.4f}')\n",
    "error_ratio_rmse = (rmse / np.mean(actual_values)) * 100\n",
    "error_ratio_mae = (mae / np.mean(actual_values)) * 100\n",
    "print(f'Error Ratio RMSE: {error_ratio_rmse:.4f}%')\n",
    "print(f'Error Ratio MAE: {error_ratio_mae:.4f}%')\n",
    "\n",
    "# Slice for 200 values for plotting\n",
    "plot_length = 200\n",
    "predictions_200 = predictions[:plot_length]\n",
    "actual_values_200 = actual_values[:plot_length]\n",
    "\n",
    "# Now we find the corresponding \"big drop\" labels for both actual and predicted values\n",
    "big_drop_actual_200 = big_drop_labels_test[ window_size: window_size + plot_length]\n",
    "big_drop_pred_200 = big_drop_predictions[:plot_length]\n",
    "\n",
    "# Plot the actual and predicted values\n",
    "plt.figure(figsize=(12, 6))\n",
    "x_range = range(len_train + window_size, len_train + window_size + plot_length)\n",
    "\n",
    "# Plot the actual bandwidth values\n",
    "plt.plot(x_range, actual_values_200, label='Actual Data', color='blue', linewidth=1.5)\n",
    "\n",
    "# Plot the predicted bandwidth values\n",
    "plt.plot(x_range, predictions_200, label='Predicted Data', color='orange', linestyle='--', linewidth=1.5)\n",
    "\n",
    "# Add blue dots for actual big drops\n",
    "for i in range(plot_length):\n",
    "    if big_drop_actual_200[i] == 1:\n",
    "        plt.scatter(x_range[i], actual_values_200[i], color='blue', s=100, marker='o', label='Actual Big Drop' if i == 0 else \"\")\n",
    "\n",
    "# Add red dots for predicted big drops\n",
    "for i in range(plot_length):\n",
    "    if big_drop_pred_200[i] == 1:\n",
    "        plt.scatter(x_range[i], predictions_200[i], color='red', s=100, marker='o', label='Predicted Big Drop' if i == 0 else \"\")\n",
    "\n",
    "# Add labels and legend\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Bandwidth\")\n",
    "plt.title(\"Actual vs Predicted Bandwidth with Big Drops (200 Samples)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
